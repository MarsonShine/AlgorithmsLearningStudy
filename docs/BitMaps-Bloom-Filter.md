# 位图：如何实现网页爬虫的URL去重功能

网页爬虫是很常见切对于搜索引擎中有重要的作用，并且爬取的数据巨大，并且要求速度要快。爬虫的工作原理是，通过解析已经爬取的页面中的链接，然后在爬取这些链接对应的网页。而同一个网页链接可能被包含在不同的页面链接中，所以这就必须要辨别被爬取的页面是否已经爬取过。如果你是一名负责开发网页爬虫的工程师，那么如何高效的爬取网页并去重呢？

最能想到的方法就是用一个哈希表来记录已经爬取过的 URL 网页链接，当爬取到这个页面时，我们在哈希表查询这个页面 URL 是否存在，存在说明是重复爬取，没有说明是新 URL，并存到哈希表中。

## 算法解析

这个问题主要是处理解析页面的 URL，需要支持的操作有两个，添加 URL 和 查询 URL。除了这两个功能性的要求方面之外，在性能方面要尽量的高效，节省内存空间。

回想我们之前学习到的数据结构与算法，我们用什么数据结构满足这一点呢？显然 红黑树，散列表，跳表这些动态的数据结构，都能快速的支持插入，查询数据，但是对内存消耗方面，在不在接受的范围内呢？

我们拿散列表举例。假设我们要爬取 10 亿个网页（像 Google，百度这样的搜索引擎，爬取的资源只会更多），为了去重，我们得维护一个 10 亿大小的散列表。那么要消耗多少内存呢？

我们假设一个 URL 的平均长度为 64 字节，那么这 10 亿个 URL，内存大约 60G 的内存空间。**因为散列表必须维持较小的装载因子，才能保证不会出现过程的哈希冲突，导致操作性能的下降**。**而且，用链表法解决散列冲突，还要存储链表指针**，如果构建这 10 亿个 URL 的散列表，所需的内存一定会高于 60G，甚至有可能会超过 100G。

对于大型的爬虫系统，即便是要求 100G 内存要求也不高，我还可以用分治法，用多台机器（比如用 20 台机器内存为 8G 的服务器）来存储这 10 亿个网页链接。

对于爬虫系统去重的问题，其实上面的思想已经可以用于生产环境工作了。不过，作为一个有追求有要求的工程师，我们应该考虑，在添加，查询的操作下效率以及内存消耗方面能不能有更好的优化方法呢？

你可能会说，用散列表的话，添加，查询数据已经是 O(1)，还能有优化空间么？事实上，我们平常所讲的时间复杂度是个根据数据规模的渐进时间变化趋势，这不能度量在一个特定的环境内的具体时间消耗。

我们平常所讲的时间复杂度都是忽略系数，常数和低阶。

如果一个时间复杂度的系数为 10，那么我们在优化过程中，能把这个系数 10 优化成 1，那时间消耗也会比之前少 10 倍，这是一个很有必要的优化。

我们用链表法解决散列冲突问题，散列表中存储的 URL，在查询的时候，通过哈希函数定位到散列表中具体的链表，还要在这个链表中查询这个 URL。这个操作是比较耗时的，主要原因有亮点。

一方面，链表中的结点存储在内存中不是连续的，所以不能一下子存储到 CPU 高速缓存中，所以数据访问性能会大打折扣。

另一方面，在查询的是字符串而不是数字，在比较时，我们用的字符串比配。显然匹配字符串的性能明显没有数字效率高。所以针对这两个方面，还是有优化空间的。

对于内存消耗的方面的优化，除了散列表之外，其实还有一个算法能让内存有明显的提升，那就是**布隆过滤器（Bloom Filter）**。

在讲布隆过滤器之前，我们先讲**位图（Bit Maps）**，这是另一种数据结构。因为布隆过滤器就是基于位图的，是对位图的一种改进。

我们先来看一个简单的问题。我们有 1 千万个整数，整数在 1 到 1亿之间。如何快速判断一个数是否在这个 1 千万个数据里面？

我们还是用散列表。不过这次用到的是特殊的散列表——位图。我们申请 1 亿大小的，数据类型为布尔类型的数组。我们将这 1 千万个整数作为下标，将对应的值设置成 true 或者 false。比如数字 5 对应数组的下标 5 的数组的值设置为 true，即 array[5] = true。

当我们查询这个数是否存在时，只需要在这个数组中对应这个数的下标的值是否等于 true 就知道是否存在了。

不过，很多语言提供的布尔类型，大小都是 1 字节的，并不能节省太多空间。实际上，标识有或没有，true 或 false 只要 1 bite 即可。**那么如何通过编程语言，来实现一个二进制位呢？**

这里就要用到位运算了。我们可以借助编程语言中提供的数据类型，比如 int、long、char 等类型，通过位运算，用其中某个位来表示某个数字。通过以下代码更好理解：

```c#
public class BitMapOfChar {
    private readonly char[] bytes;
    private readonly int nbit;
    private readonly int bitCount = sizeof(char) * 8;
    public BitMapOfChar(int nbit) {
        this.nbit = nbit;
        bytes = new char[nbit / bitCount + 1];
    }
    public void Set(int k) {
        if (k > nbit) return;
        int byteIndex = k / bitCount;
        int bitIndex = k % bitCount;
        bytes[byteIndex] |= (char) (1 << bitIndex);
    }
    public bool GetBoolean(int k) {
        if (k > nbit) return false;
        int byteIndex = k / bitCount;
        int bitIndex = k % bitCount;
        return (bytes[byteIndex] & (1 << bitIndex)) != 0;
    }
}
```

> 注意：不同的语言 / 平台不同的数据类型所占字节是有所差异的，Java 中 char 类型占 16bit，2 字节。C# 中如 int 分系统平台位数，32 位系统占 4 字节，64 位系统占 8 字节，而 bool 类型占 1 个字节。

从刚刚位图结构的讲解中，可以发现，通过数组下标来定位数据，所以查询效率非常高。而且，每个数字是通过一个二进制位表示的，在范围不大的情况下，所需内存是非常小的。

就说刚才的例子，如果用散列表存储 1 千万的数据，数据是 32 位的整形，也就是每个数字需要 4 个字节存储空间，总共需要 40 MB 的内存空间。如果我们通过位图来表示，数字范围在 1 到 1亿之间，只需要 1 亿二进制位，也就是大约只需要 12 MB 的内存空间即可。

关于位图我们就讲完了，是不是很简单？不过这里有个限制条件，那就是数字范围在 1 到 1亿之间，如果范围变大一些，1 到 10 亿之间的 1 千万的数据，内存却翻了 10 倍，所需内存即 120MB，不降反升。

这种情况下，布隆过滤器就是为了解决这个问题的，是对位图数据结构的一种改进。

还是刚刚的那个例子，数据个数是 1 千万个，数据范围是 1 到 10 亿。布隆过滤器的做法是，任然使用 1 亿个二进制位大小，然后用哈希函数，对数字进行处理，是这个数据落在这 1 亿个二进制中。比如我们把哈希函数设计成 f(x)=x%n。其中 n 表示位图的大小，x 表示该数字，也就是拿数字对位图的大小进行取模运算。

不过你肯定会说，这样设计有明显的问题，当数据超过 1 亿不久重复么？比如 一亿零一取模运算得的值是 1，和 1 取模运算是重复的，这样就无法区分这两个数了。

当然这只是一个简单的哈希函数设计方式，这种情况下的确会冲突，但是我们可以其他方式来降低这种冲突，那么具体用什么方式呢？我们来看下布隆过滤器是如何做到的。

我们使用 K 个哈希函数，对同一个数字进行哈希求职，必然会得到不同的值，我们分别记为 X1，X2...，Xk。我们把这 K 个数字作为位图的下标，将对应的位图值设为 true，即 BitMaps[X1]，BitMaps[X2]...，BitMaps[Xk] 设为 true。也就是说我们用 K 个二进制位来表示这个数字存不存在。

![img](https://static001.geekbang.org/resource/image/94/ae/94630c1c3b7657f560a1825bd9d02cae.jpg)

布隆过滤器误判有一个特点，那就是如果布隆过滤器判断这个数不存在，那么就一定不会发生误判，如果这个数据判断存在，那么有可能这个数不存在，会发生误判。不过，我们只要针对哈希函数的个数，位图的大小跟存储数字的个数之间的比例就能大幅度降低这种误判的概率。

虽然布隆过滤器会发生误判，但是这不影响它的正常使用。针对爬虫引擎来说，爬取 10 亿个页面，发生几次重复的误判，也不会影响整个爬取使用。毕竟这么多页面，爬虫引擎也不是能保证 100% 都能爬取到。

针对上面的例子，页面个数为 10 亿个，我们可以用 10 倍页面个数大小的位图来存储，也就是 100 亿个二进制位，换算成字节，大概是 1.2G。之前我们用散列表判断去重，得用 120G 内存。相比之下，布隆过滤器节省了大量的空间。

我们再来看下，布隆过滤器算法的执行效率对比与散列表的执行效率，布隆过滤器的计算主要消耗在对 URL 进行多个哈希求值，因为是对数字下标的操作，所以这是非常快速的，并且是 CPU 密集型操作。而散列表是对 URL 进行一次哈希先得到一个链条的位置，然后在这个列表中遍历所有的 URL 判断这个 URL 是否与指定查询的匹配，并且是字符串匹配，所以执行效率肯定是布隆过滤器要由于散列表的。

## 总结拓展

我们从爬虫爬取 URL 功能从散列表讲到位图，在从位图讲到布隆过滤器。布隆过滤器非常适合不是 100% 准确的，允许小概率误判的大规模去重场景。除了爬虫案例，还有网站的 PV，UV 统计也可以使用布隆过滤器，对重复访问的用户去重。

我们前面讲到了，误判率是跟位图大小，数据个数有关的。当我们不停的往过滤器添加数据时，位图的位置就会越来越小，这样误判的概率就会增加，所以对于我们无法提前知道数据的个数时，我们要支持动态扩容。

当数据个数与位图大小的比例超过某个阈值的时候，我们就应该重新申请一个新的位图。后面的新数据会放置到新的位图中。但是这样的话，我们判断某个数字是否存在就不能只在一个位图中判断了，要在每个位图中都要判断，这样执行的效率就会降低一些。
# 贪心算法

贪心算法有很多经典应用，比如霍夫曼编码、Prim 和 Kruskal 最小生成树算法、还有 Dijkstra 单源最短路径算法。最小生成树和最短路径算法我们后面会讲到，今天来讲一下霍夫曼编码。

**霍夫曼编码（Huffman Coding）实现对数据压缩编码，有效节省数据存储空间的。**

我们先来模拟一个场景，假设我们有一个可以容纳 100kg 物品的背包，可以装载各种物品。我们有以下 5 种豆子，每种豆子的总量和总价值都不相同。为了让背包中所装物品的总价值最大，我们如何选择在背包中装那些豆子？每种豆子又该装多少？

![](https://static001.geekbang.org/resource/image/f9/c7/f93f4567168d3bc65688a785b76753c7.jpg)

我们很容易就能知道，只需要按价格从高到低依次来装就好了。单价从高到低排列，依次就是黑豆、绿豆、红豆、青豆、黄豆，所以可以往背包里装 20kg 黑豆、30kg 绿豆、50kg 红豆。这种我们就可以用贪心算法：

**第一步，当我们看到这类问题的时候，首先要联想到贪心算法**：针对一组数据，我们定义了限制值和期望值，我们从中选出几个数据，**在满足限制条件的情况下，期望值更大。**

类比到刚刚的例子，限制值就是重量不能超过 100kg，期望值就是物品的价值。这组数据就是 5 种豆子。我们从中选出一部分，满足重量不超过 100kg，而且总价值最大。

**第二步，我们尝试看下这个问题是否可以用贪心算法：**每次选择当前情况下，在对限制值同等贡献量的情况下，对期望值贡献最大的数据。

类比到例子，我们选择物品都是取重量相同的，价格最贵的（期望值贡献最大）。

**第三步，我们举几个例子看下贪心算法产生的结果是否是最优的。**大部分情况下，要严格验证贪心算法的正确性，是非常复杂的，需要涉及比较多的数学推理。从实践的角度讲，大部分能用贪心算法解决的问题，贪心算法的正确性都是显而易见的，也不需要严格的数学推导证明。

实际上，用贪心算法解决问题的思路，并不是最优解。

比如在一个带权位图中，我们从某个起点 S 开始，到指定终点 T 的最短路径。如果按照贪心算法的思想，我的每次选择都是最小的，直到顶点 T。所以按照这个算法，我们求出的最短路径是 S->A->E->T，路径长度是 1+4+4=9。

![img](https://static001.geekbang.org/resource/image/2d/42/2de91c0afb0912378c5acf32a173f642.jpg)

但是我们知道这并不是最短距离，而是 S->B->D->T，路径长度是2+2+2=6。那么贪心算法在这个问题为什么就不起作用了呢？

主要原因是第一次的选择会直接影响后面的选择的结果，也就是说你第一次选择虽然是当前选择的最优解，但是这不代表后续的选择都是最优解，有可能后续的操作都是坏的结果，从而导致整个结果不是最优解。

# 贪心算法实例分析

## 分糖果

我们有 m 个糖果和 n 个孩子。我们现在要把糖果分给这些孩子吃，但是糖果少，孩子多（m<n），所以糖果只能分给部分孩子。那么如何分配糖果，才能尽可能分给更多的孩子？

我们根据前面的步骤分析，要分析两个值，限制值和期望值。很显然，糖果的数量 m 就是限制值，而期望值就是孩子对糖果的需求（看孩子是要小糖就可以了，还是要大糖）。那么这样我们就可以需求小的开始来满足孩子。我们每次从剩下的孩子中，选择对糖果需求最小的，这样就能满足孩子的个数是最多的。

## 钱笔找零

这个例子我们经常常见，假设我们有一系列币种 1元，2元，5元，10元，20元，50元，100元，他们的张数分别是C1、C2、C5、C10、C20、C50、C100。我们要这些钱来支付 K 元，要求用数量最少的纸币。

用贪心算法同样我们可以分析两个值，K 元就是限制值，钱币数量最少是期望值。

这个很容易就能得出思路：首先我们用面值最大的来支付，如果不够就用相对第二小的面值支付，依次类推到 1 元。

## 区间覆盖

假设我们有 n 个期间，区间的起始点和结束点分别是 [l1,r1]，[l1,r2]，[l3,r3]，……，[ln,rn]。我们从中选出两两不相交的区间（端点相交的情况不算），最多能选出多少个区间？

![img](https://static001.geekbang.org/resource/image/f0/cd/f0a1b7978711651d9f084d19a70805cd.jpg)

思路：我们从两端开始假设最左端是 lmin，最右端是 lmax。要找出最多的两两不相交的区间，那么就得满足区间间隔小的，且区间与区间之间不能含有重复元素，所以我们在选择的时候，左端点跟前面已经覆盖的区间不重合，右端点尽量小，这样就能容纳更多的区间。

![img](https://static001.geekbang.org/resource/image/ef/b5/ef2d0bd8284cb6e69294566a45b0e2b5.jpg)

# 霍夫曼编码（Huffman Coding）

假设我们有 1000 个字符的文件，每个字符占 1 个 byte（1byte=8bit），存储这个 1000 个就需要 8000 bits，那有没有更加节省空间的存储方式呢？

假设我们通过统计发现，这 1000 个字符中只包含 6 种不同的字符，假设它们分别是a、b、c、d、e、f。而三个二进制位就可以表示 8 个不同的字符，所以为了尽量减少存储空间，我们可以用 3 个二进制位来表示。那存储这 1000 个字符就只需要 3000 个 bits 就可以了，比原来的存储方式节省了很多空间。不过，还有没有更加节省存储空间的存储方式呢？

```
a(000)、b(001)、c(010)、d(011)、e(100)、f(101)
```

霍夫曼就要登场了。霍夫曼编码是一种十分有效的编码方法，广泛用于数据压缩，其中压缩率通常在 20%-90%之间。

霍夫曼不仅考察文本中有多少不同的字符，还会考察每个字符出现的频率，根据频率的不同，选择不同长度的编码。霍夫曼正是利用这种不等长的编码方法，来进一步压缩。如何给不同频率的字符选择不同长度的编码呢？根据贪心算法思想，我们可以把出现频率比较高的字符，用稍微短的一些编码；出现频率比较少的字符，就用稍微长的编码。

比如之前提到的例子，我们用 3 位二进制位表示一个字符。这样的话，我们可以每次从文本中读取 3 位二进制树，然后转换成对应的字符。但是由于霍夫曼是不等长的，每次应该读取 1 位还是 2 位？这个问题就比较复杂了。**为了避免压缩过程中的歧义，霍夫曼编码要求各个字符的编码之间，不会出现某个编码是另一个编码前缀的情况**

![img](https://static001.geekbang.org/resource/image/02/29/02ad3e02429b294412fb1cff1b3d3829.jpg)

假设 6 个字符出现的频率从高到低分别为 a、b、c、d、e、f。任何一个字符编码都不是另一个的前缀，在压缩的时候，尽可能的读取长的可解压的二进制串，所以在解决的时候也不会产生歧义。经过这种编码压缩之后，1000 个字符就只需要 2100 个字符就可以了。

![img](https://static001.geekbang.org/resource/image/83/45/83921e609c8a4dc81ca5b90c8b4cd745.jpg)

如何根据字符串出现的频率的不同，给不同的字符进行不同长度的编码？

我们把每个字符都看作是一个结点，并且附带把频率放倒优先级队列中。我们从队列中取最小的两个子结点 A，B，然后新建一个结点 C，把频率设置为 A，B 频率之和，并把 C 作为 A，B 两结点的负结点。然后再把 C 结点放入优先级队列中。重复这个过程，直至没有数据。

![img](https://static001.geekbang.org/resource/image/7b/7a/7b6a08e7df45eac66820b959c64f877a.jpg)

现在我们统一在每一条边上加上权值，左边子结点的权值就是 0 ，指向右结点的边都是 1，从跟结点到叶子结点的路径对应的字符就是霍夫曼编码。

![img](https://static001.geekbang.org/resource/image/cc/ed/ccf15d048be005924a409574dce143ed.jpg)

# 思考练习

Q：在一个非负整数中，我们要移除 k 位数字，使这个数最小，如何移除呢？

A：要使一个数最小，那么最高位值肯定不能最大，即值最小，这是期望值，并且要移除 k 位，这是限制条件。我们能很容易的得出，我们应该从最高位开始与后一位比较，如果最高位大，则移除，反之，就往下移一位继续与后后一位比较，循环 k 次，如：有这么一串数字 45634987650。第一次比较：4 与 5 比较，最高位是要比 5 小的，所以往低位进 1，继续往低位比较，则是 5 与 6 比较，还是一样，继续拿 6 和 3 比较，我们发现高位是比低位要大的，所以移除，就变成了 4534987650；第二次比较过程与第一次一样，当我们比较到 5 和 3 时，删除 5 就变成了 434987650，依次类推到第五次的结果分别是 34987650，3487650，347650。即移除 5 位最小的值就是 347650。

